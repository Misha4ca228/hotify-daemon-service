import asyncio
import json
import time
from copy import deepcopy

from torch.distributed.elastic.multiprocessing import start_processes

from daemon.core import loader
from loguru import logger

from daemon.database.db import sessionmaker
import aio_pika
import daemon.core.config as cfg
from daemon.database.models.task import TasksStatus
from daemon.services.character import get_character_by_id
from daemon.services.dialogs import get_dialog_by_user_id
from daemon.services.node import get_node, update_node
from daemon.services.rmq import publish
from daemon.services.tasks import get_task, update_task
from daemon.utils.generate_image import save_and_gen


async def main():
    connection = await aio_pika.connect_robust(cfg.RABBIT_URL)
    async with connection:
        channel = await connection.channel()
        await channel.set_qos(prefetch_count=1)

        queue = await channel.declare_queue(cfg.QUEUE_NAME, durable=True)

        async with queue.iterator() as queue_iter:
            async for message in queue_iter:
                async with message.process():
                    pyload_str = message.body.decode()
                    try:
                        pyload = json.loads(pyload_str)
                    except json.JSONDecodeError:
                        continue

                    task_id = pyload.get("id", None)
                    if not task_id:
                        continue

                    async with sessionmaker() as session:
                        logger.info("Start Generation")
                        start_processing = time.time()
                        task = await get_task(session=session, task_id=task_id)
                        dialog = await get_dialog_by_user_id(session=session, user_id=int(task.user_id))
                        character = await get_character_by_id(session, dialog.character_id)
                        node = await get_node(session, cfg.NODE_ID)

                        if task.image_args:
                            function_args = task.image_args
                            start_image_gen = time.time()
                            url = await asyncio.to_thread(save_and_gen, node.worker_url, character.name, **function_args)
                            logger.info(f"Photo generated by: {round(time.time() - start_image_gen, 2)}s")
                            await update_task(session=session, task_id=task_id,
                                              status=TasksStatus.WAIT_SEND.value,
                                              image=url)
                            payload = {"id": task.id, "status": task.status}
                            logger.info(f"image generate {url.split("/")[-1]}")
                            await publish(loader.exchange, "message", payload)

                            await update_node(session, node_id=cfg.NODE_ID, profit=node.profit+cfg.PROFIT)


                        else:
                            await update_task(session=session, task_id=task_id,
                                              status=TasksStatus.WAIT_SEND.value)

                            payload = {"id": task.id, "status": task.status}
                            await publish(loader.exchange, "message", payload)
                        logger.info(f"Total processing time: {round(time.time()-start_processing, 2)}s")
                        logger.info(f"+{round(cfg.PROFIT, 2)}₽")
                        logger.info(f"Total profit: {round(node.profit, 2)}₽")
                        logger.info("-" * 50)


if __name__ == "__main__":
    logger.info("Service started!")
    asyncio.run(main())
